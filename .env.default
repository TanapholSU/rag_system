# OpenAI API KEY
OPENAI_API_KEY=

# Vector database url
LLM_VECTOR_DB_URL=http://qdrant:6333

# Vector database collection name
LLM_VECTOR_DB_COLLECTION_NAME=tektome

# During LLM process, the large document is splitted for vector embedding and query process.
# This parameter specifies the chunk size of the splitted text
LLM_PREPROCESS_CHUNK_SIZE=128

# Specified the chunk overlap parameter during document splitting
LLM_PREPROCESS_CHUNK_OVERLAP=20

# Maximum mumber of relevant documents to be retrieved from vector db
LLM_VECTOR_SEARCH_TOP_K=1

# Service endpoint of object storage. No need to include http://
STORAGE_SERVICE_ENDPOINT=minio:9000

# access key for the object storage
STORAGE_ACCESS_KEY=tektome

# secret key for accessing the object storage
STORAGE_SECRET_KEY=tektomeSecret

# target bucket name
STORAGE_BUCKET_NAME=tektome

# type of connection to object storage
STORAGE_SECURE_CONNECTION=False

# Celery is used to process long running ocr task.
# This parameter is for celery broker url (message communication)
CELERY_BROKER_URL=redis://redis:6379/0

# Celery result backend url (for storing result and state of the task)
CELERY_RESULT_BACKEND_URL=redis://redis:6379/0

# DEBUG mode. Default value is  False. If it's True, it outputs stacktrace in every error response obtained from API 
DEBUG=False